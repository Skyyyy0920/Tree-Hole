<div align="center">
<img src="./landscape-1192669_1920.jpg" width=150%/>
</div>

`论文阅读笔记`

@[TOC](目录)

---

# 一、基本信息

1. 标题：*Federated Boosted Decision Trees with Differential Privacy*

2. 发表时间：2022

3. 出版源：2022 ACM SIGSAC Conference on Computer and Communications Security

4. 领域：Computer and Communications Security

5. 摘要：

    目前，对于可伸缩的、安全的、高效的、能在分布式数据上进行训练的保护隐私的机器学习模型有很大的需求。虽然深度学习模型通常在集中的非安全设置中获得最好的结果，但当施加隐私和通信限制时，不同的模型也可以表现得更好。相反，基于树的方法(如XGBoost)因其高性能和易用性而引起了广泛关注;特别是，他们经常在表格数据上获得最先进的结果。因此，最近的一些工作集中于通过同态加密(HE)和安全多方计算(MPC)等加密机制，将梯度增强决策树(GBDT)模型(如XGBoost)转换为联邦设置。然而，它们并不总是提供正式的隐私保证，或考虑所有超参数和实现设置。在本研究中，我们实现了差分隐私(DP)下的GBDT模型。我们提出了一个捕捉和扩展现有差分私有决策树方法的一般框架。我们的方法框架是为联邦设置量身定制的，我们表明，通过仔细选择技术，可以在保持高度隐私的同时实现非常高的效用

6. 主要链接：
   - Paper：<https://arxiv.org/abs/2204.04540>
   - Github：<https://github.com/Samuel-Maddock/federated-boosted-dp-trees>
   - 有关联邦学习的补充知识：<https://zhuanlan.zhihu.com/p/79284686> <https://cloud.tencent.com/developer/article/1489037>
   - XGboost补充知识：<https://zhuanlan.zhihu.com/p/162001079> <https://blog.csdn.net/Datawhale/article/details/103725122> <https://zhuanlan.zhihu.com/p/258564378>

---

# 二、研究背景

## 1. 问题定义

众所周知，机器学习模型会泄露训练集中个人的私人信息。差别隐私是一个流行的定义，它是为了减轻这种隐私风险而开发的，近年来已成为隐私的主要概念。目前很多关于私有机器学习的研究都集中在训练具有不同隐私性的深度学习模型。DP通常与联合学习相结合，其中数据驻留在客户端设备上，只从客户端收集关于模型更新的少量信息，以便进一步最小化隐私风险。

尽管深度学习模型对于集中设置中的一系列现实任务非常强大，但它们有时会被表格数据集上的“更简单”模型击败。其中一个竞争对手是梯度增强决策树(gbdt)。GBDT方法构建了一个弱决策树的集合，逐步纠正过去训练中的错误，以提高预测。许多GBDT框架，如XGBoost， LightGBM和CatBoost已经被广泛采用由于GBDT方法的速度、可扩展性、易用性以及在表格数据集上令人印象深刻的性能，它是深度学习的一种有吸引力的替代方法。

最近的工作研究了联邦设置下安全训练下的GBDT实现，如XGBoost。这些方法通常依赖于密码技术，如同态加密(HE)或安全多方计算(MPC)。虽然这允许GBDT模型的安全联合训练，而不需要任何参与者直接发布他们的数据，但最终模型不一定是私有的，也不能保证正式的差异隐私(DP)。例如，在决策树的情况下，树中的分裂决策可以直接揭示有关训练集的敏感信息。此外，这种对重量级加密技术(如HE或MPC)的依赖往往使方法计算密集或需要大量的通信轮，使它们难以扩展到超过几个参与者的范围。

与此同时，许多工作都对DP中心模型下的决策树模型进行了研究。大多数研究都集中在随机森林(RF)模型的训练上，而很少有研究探讨梯度增强和DP之间的权衡;那些经常使用中央DP机制的应用程序，不容易扩展到联邦设置。因此，在联邦DP设置中实现gbdt仍然是一个开放的问题，并展示如何获得与它们的集中式非私有对应程序相当的实用程序。

我们的重点是通过轻量级MPC方法(如安全聚合)在联邦设置中操作的DP-GBDT方法。这种设置最近变得引人注目，因为它承诺在中央DP技术的计算效率和加密方法的安全性之间进行有吸引力的权衡。最近考虑gbdt的联邦工作提出了DP局部模型下的方法，但由于使用了局部噪声，在效用上产生了显著损失。

在本文中，我们将现有的方法集中在一个统一的框架下，在该框架中我们提出了满足DP的技术，这些技术非常适合联邦设置。我们发现，通过剖析GBDT算法的组成部分，并仔细考虑算法的每个组成部分的选项，我们可以确定实现隐私和实用的最佳平衡的特定组合。我们还强调可以在少量通信轮中训练这种私有GBDT模型的变体，这对联邦设置特别重要。

我们更进一步的发现是，使用GBDT模型可以实现高性能，甚至可以与非私有方法相比。为了做到这一点，我们必须将隐私预算分配到对学习过程最重要的数量上。例如，我们表明，在计算树的分割决策上花费太多的算力并不像在叶权重上花费那么重要。在Renyi差分隐私(RDP)的高效隐私核算下使用我们的发现，其性能比以前的工作中看到的更接近非隐私设置。

## 2. 主要贡献

- 一个清晰简洁的差分私有梯度增强决策树框架。我们将GBDT算法分解为五个主要组件，展示了如何在满足Rényi差异隐私(RDP)的同时联合每个组件。我们提出了一种统一的方法，捕获了最近提出的基于DP树的模型作为特殊情况。

- 一组用于提高私有联邦GBDT模型效用的新技术。例如，我们提出了一种用于离散连续特征的私有方法，该方法尽可能多地利用私有训练信息，几乎不增加额外的隐私成本。此外，我们还探索了批处理权重更新，表明在减少所需的通信轮数的同时，有可能保持有竞争力的模型性能。

- 在一系列基准数据集上进行大量的实验，探索在我们的框架中各种选项之间的权衡。通过评估我们的框架中每个组件的选择，我们发现通过调整和简化GBDT算法，并将其与改进的分裂候选方法相结合，形成了一个明确的优势方法。我们表明，在具有合理隐私水平的一系列数据集上，它可能比最先进的(SOTA) DP-RF和DP-GBDT方法获得更高的效用。

## 3. 前置知识

1. Gradient Boosted Decision Trees (GBDT)
2. Differential Privacy (DP)
3. The Federated Model of Computation

## 4. 相关工作

差别私有决策树在中心环境下得到了很好的研究，其重点是随机森林(RF)模型。然而，改进的方法(即私有GBDT模型)还没有得到很好的研究。最近，联邦XGBoost模型被提出，大多数工作集中于通过同态加密(HE)和安全多方计算(MPC)等密码原语进行安全训练，并且没有DP保证。

一些相关的工作研究了具有本地DP (LDP)保证的联邦设置中的XGBoost。在这方面与我们最接近的工作是FEVERLESS方法，它使用安全聚合和高斯机制将XGBoost算法转换为垂直联邦设置。特别是，FEVERLESS将梯度信息安全地聚合到一个私有直方图中，该直方图用于计算分割分数和叶权重。选择特定的参与者子集作为“噪声领导者”，在聚合前将高斯噪声添加到他们的梯度信息中，在所有参与者之间安全聚合后实现总体DP保证。正如我们将看到的，以这种方式直接翻译XGBoost算法的主要缺点是重复计算分割分数的高隐私成本。这导致必须在分割分数/叶重量计算中添加更多的噪声和较低的实用新型。

为了减少这种隐私成本，可以考虑独立于数据进行分割决策。这些所谓的完全随机(TR)树已经被研究在非私有和私有环境下的随机森林。在私有环境中，提出的方法通常使用难以联合的中央DP机制。例如，Fletcher和Islam提出了一种DPRF方法，在光滑灵敏度的概念下，利用指数机制输出叶节点中的多数标签，不适合联邦设置。

在这项工作中，我们还考虑TR树作为我们框架下的一个选项，但用于联邦和私有的GBDT模型。据我们所知，唯一考虑使用随机树进行私有增强的其他工作是Nori等人的工作。他们考虑了一个中央DP设置，专注于通过可解释推进机(ebm)训练私有可解释模型。

---

# 三、实现方法

---

# 四、创新点

---

# 五、实验细节

## 1. 实验设置

## 2. 实验结果

---

# 六、总结

我们提出了一个在联邦环境下GBDT模型差分私有训练的框架。通过在框架的每个阶段评估不同的选项，我们找到了一种基于随机分割、牛顿更新、循环训练和迭代Hessian (IH)方法的主要方法。我们的方法通常在一系列数据集和模型结果上优于SOTA方法，其性能接近于非私有的对应方法。当与批处理更新相结合时，只需少量的通信轮就可以训练模型，性能损失很小。
