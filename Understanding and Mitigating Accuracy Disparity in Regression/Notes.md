<div align="center">
<img src="./cat-g86cc85e99_1920.jpg" width=150%/>
</div>

`论文阅读笔记`

@[TOC](目录)

---

# 一、基本信息

1. 标题：*Understanding and Mitigating Accuracy Disparity in Regression*

2. 发表时间：2021

3. 出版源：ICML

4. 领域：Machine Learning

5. 摘要：
   
    随着大规模预测系统在高风险领域(如人脸识别、刑事司法等)的广泛部署，不同人口统计子群体之间预测精度的差异要求对这种差异的来源和算法干预进行根本性的了解，以缓解这种差异。本文研究了回归中的精度差异问题。首先，我们提出了一个误差分解定理，将精度差异分解为边际标签分布之间的距离和条件表示之间的距离，以帮助解释在实践中为什么会出现这种精度差异。

    基于这种误差分解和统计距离分布一致性的一般思想，我们提出了一种减小这种差异的算法，并分析了所提出的目标函数的博弈论优化。为了证实我们的理论发现，我们还在五个基准数据集上进行了实验。实验结果表明，我们提出的算法在保持回归模型预测能力的同时，可以有效地减小精度差异。

6. 主要链接：
   - Paper：https://arxiv.org/pdf/2102.12013.pdf
   - GitHub：


---

# 二、研究背景

## 1. 问题定义

机器学习的最新进展使得它在许多高风险领域得到了广泛应用，比如刑事司法、医疗保健、学生贷款审批和招聘。

同时，人们也广泛观察到，在实践中，在各种场景下，准确率差异可能会在不经意间发生。例如，错误倾向于发生在某些代表性不足的人口统计群体的个人。不同的私有模型甚至会加剧这种准确性差异。这种跨人口统计子群体的准确性差异不仅引起了人们对高风险应用程序的担忧，而且还可能被恶意方利用，造成信息泄漏。

我们的目标是学习一个公平的回归模型：相对于敏感属性A的分组中，回归器的误差近似相等。我们假设敏感属性a只在训练阶段对学习者可用，在推理阶段不可见。我们想指出的是，即使在群体公平的子类别中，也有许多其他不同和重要的公平定义(Narayanan, 2018)，我们的讨论绝不是全面的。例如，文献中经常使用的公平性定义是所谓的统计平价(Dwork等人，2012)和均等几率(Hardt等人，2016)。尽管如此，在本文中，我们主要将准确性均等作为我们的公平性概念，因为事实证明，机器学习系统在不同人口统计子群体之间表现出了实质性的准确性差异(Barocas和Selbst, 2016;金正日,2016;Buolamwini和Gebru, 2018)。这个观察结果已经引起了公众的广泛关注(例如，参见《纽约时报》、《V erge》和《保险杂志》)，并呼吁(至少大致)满足精度平价的机器学习系统。例如，在一个医疗支出预测系统中，涉众不希望不同人口统计子组之间的预测误差差距太大。

## 2. 主要贡献

在本文中，我们提供了一个精确度差异的规定性分析，旨在提供算法干预以减少回归环境中不同人口统计子群体之间的差异差距。

首先，我们首先通过描述潜在的群智慧误差的可行区域，形式化地描述了为什么精度差异出现在回归问题中。接下来，我们推导了一个误差分解定理，将精度差异分解为边缘标签分布之间的距离和条件代表之间的距离。我们还提供了组间联合误差的下界。基于这些结果，我们说明了为什么当边际标签分布或条件表示在组间不同时，以最小化全局损失为目标的回归模型将不可避免地导致精度差异。

在误差分解定理的激励下，我们提出了两种算法，分别通过与总变异距离和Wasserstein距离联合分布对齐来减小精度差异。此外，我们分析了目标函数的博弈论最优解，并从博弈论的角度说明了我们的算法原理。为了验证我们提出的算法在减少精度差异方面的有效性，我们在五个基准数据集上进行了实验。实验结果表明，我们提出的算法在保持回归模型预测能力的同时，有助于减小精度差异。我们相信我们的理论结果有助于理解为什么在机器学习模型中会出现精度差异，并且提出的算法提供了一种干预现实场景的替代方案，在现实场景中，需要精度均等，但收集更多的数据/特征是耗时或不可行的。
   
## 3. 相关工作


---

# 三、实现方法


---

# 四、创新点


---

# 五、实验细节

## 1. 实验设置

## 2. 实验结果

---

# 六、总结

本文从理论上和实证上研究了回归问题中的精度差异问题。具体而言，我们证明了联合误差的信息论下界和跨群误差间隙的互补上界，以描述群误差的可行域。我们的理论结果表明，由于边缘标签分布在组间的差异，准确性差异不可避免地会出现。为了减少这种差异，我们进一步提出通过使用统计距离学习条件群不变表示来实现精度奇偶。

在精度差异最小的情况下，我们所提出的方法的目标函数达到了博弈论的最优。我们在五个基准数据集上的实证结果表明，我们提出的算法有助于有效地减少精度差异。我们相信，我们的结果为更好地理解机器学习模型的准确性差异迈出了重要的一步。

